{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf29c411",
   "metadata": {},
   "source": [
    "Note that this notebook is fully created from stract by Ujjwal Basnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c4b86a",
   "metadata": {},
   "source": [
    "## Definitions\n",
    "- **Accuracy**: The proportion of correctly classified samples among all the samples in the dataset.\n",
    "\n",
    "\n",
    "- **Precision**: Precision is the proportion of positive predictions that are true positives\n",
    "--------------------------------------------------------------------------------------------------------------------------\n",
    "     precision tells us how often the model is correct when it predicts a positive sample. A high precision score means that the model is making fewer false positive predictions\n",
    "     \n",
    "--------------------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "- **Recall**: (also known as sensitivity or true positive rate ) is the proportion of actual positive samples that the model correctly identified as positive.\n",
    "--------------------------------------------------------------------------------------------------------------------------\n",
    "    recall tells us how often the model correctly identifies positive samples out of all the actual positive samples. A \n",
    "    high recall score means that the model is making fewer false negative predictions.\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "- ****F1 score****: The harmonic mean of precision and recall. It balances the trade-off between precision and recall, and provides a single score to evaluate the overall performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1354c2da",
   "metadata": {},
   "source": [
    "## Note \n",
    "- **Recall**  is important in cases where false negatives are more costly than false positives. For example, in medical diagnosis, a false negative result (i.e., a patient with a disease being incorrectly identified as healthy) can have severe consequences, while a false positive (i.e., a healthy patient being incorrectly identified as having a disease) can be corrected with further testing\n",
    "--------------------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "- **Precision**  is an important metric in situations where false positives are more costly than false negatives. For example, in a spam email filter, a false positive (i.e., a legitimate email being incorrectly classified as spam) can be very annoying for the user ,\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "  while a false negative (i.e., a spam email being classified as legitimate) can be ignored or deleted by the user. In this   case, a high precision score is desirable, even if it comes at the cost of a lower recall score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336307b4",
   "metadata": {},
   "source": [
    "# IMPLEMENTATIONS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8b2a66",
   "metadata": {},
   "source": [
    "### recall = TP / (TP + FN)\n",
    "### precision = TP / (TP + FP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da08ad0",
   "metadata": {},
   "source": [
    "#### creating a classificaion data sets containing 100 samples of which 90 belongs to class A and 10 samples belongs to class B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ae868b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e7c91886",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "# For Two class A and B \n",
    "#lets create 90 rows and 3 columsn  Class A \n",
    "# and class B of 10 rows 3 columns \n",
    "\n",
    "A = np.random.normal(size = (90 , 3 ))\n",
    "B = np.random.normal(size = (10 , 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "296d69ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90, 3), (10, 3))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape , B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0dc7fe72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dc8ae5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.62434536, -0.61175641, -0.52817175],\n",
       "       [-1.07296862,  0.86540763, -2.3015387 ],\n",
       "       [ 1.74481176, -0.7612069 ,  0.3190391 ],\n",
       "       [-0.24937038,  1.46210794, -2.06014071],\n",
       "       [-0.3224172 , -0.38405435,  1.13376944]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now contatinate two classes to create a features \n",
    "features = np.concatenate([A , B])\n",
    "#looking into only 5 samples hai \n",
    "features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "29543141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets create target \n",
    "a = np.zeros(90)\n",
    "b = np.ones(10)\n",
    "targets = np.concatenate([a , b ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "67892cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c5087f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  DATA SETS SANO BAKO LE TRAIN TEST SPLIT GARINA HAI "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8c1343",
   "metadata": {},
   "source": [
    "#### Apllying "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c9ec441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import  precision_score , recall_score , f1_score , accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "702fe177",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4c281e0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(features , targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "07cf8fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74066829",
   "metadata": {},
   "source": [
    "### Calculating metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "55f06f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "precision_score_ = precision_score(targets , y_pred)\n",
    "recall_score_ = recall_score(targets  , y_pred )\n",
    "f1_score_ = f1_score(targets , y_pred)\n",
    "accuracy_score = accuracy_score(targets , y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41f34c0",
   "metadata": {},
   "source": [
    "## Creating Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "79e46a6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix of \n",
      "    0  1\n",
      "0  90  0\n",
      "1  10  0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"confusion matrix of \")\n",
    "print(pd.DataFrame(confusion_matrix(targets , y_pred ) , columns = [0 , 1 ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28411a3",
   "metadata": {},
   "source": [
    "- there are 90 instances that are truly labeled as 0 and predicted as 0 (true negatives),\n",
    "- and 10 instances that are truly labeled as 1 but predicted as 0 (false negatives). \n",
    "- There are no instances that are truly labeled as 0 but predicted as 1 (false positives),\n",
    "- and no instances that are truly labeled as 1 and predicted as 1 (true positives)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2775e2ac",
   "metadata": {},
   "source": [
    "This confusion matrix indicates that the model is correctly identifying all instances that belong to class 0, but is failing to identify any instances that belong to class 1. The lack of any true positives in the matrix suggests that the model is not successfully discriminating between the two classes, and may be classifying all instances as class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a9b8a10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision score 0.0\n",
      "recall score  0.0\n",
      "f1 score  0.0\n",
      "accuracy_score 0.9\n"
     ]
    }
   ],
   "source": [
    "print(\"precision score\" , precision_score_ )\n",
    "print(\"recall score \" , recall_score_)\n",
    "print(\"f1 score \" , f1_score_)\n",
    "print(\"accuracy_score\", accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf80fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cda139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adcfc84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69035e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965dc1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
